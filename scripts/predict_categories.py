import json
import re
from pathlib import Path
from transformers import pipeline
from langdetect import detect
from tqdm import tqdm


# === Normalisation pour l'arabe ===
def normalize_arabic(text):
    text = re.sub(r'[Ø£Ø¥Ø¢Ù±]', 'Ø§', text)
    text = re.sub(r'[\u064B-\u065F]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

# === Nettoyage gÃ©nÃ©ral ===
def is_mostly_numeric_or_symbolic(text):
    cleaned = re.sub(r'\s+', '', text)
    if not cleaned:
        return True
    non_alpha = sum(1 for c in cleaned if not (c.isalpha() or c in ' .,-/'))
    return non_alpha / len(cleaned) > 0.8

def clean_summary(text, is_french=False):
    text = re.sub(r'[|*+()\[\]{}:;]+', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text.lower() if is_french else normalize_arabic(text)

def preprocess_text(text):
    try:
        lang = detect(text)
        is_french = lang == 'fr'
    except:
        is_french = False
    cleaned_text = clean_summary(text, is_french)
    if len(cleaned_text) < 20 or is_mostly_numeric_or_symbolic(cleaned_text):
        return None
    return cleaned_text


# === Mapping ID â†’ catÃ©gorie arabe/franÃ§ais
category_names = {
    "Actes judiciaires": "Ø§Ø¬Ø±Ø§Ø¡Ø§Øª Ø¹Ø¯Ù„ÙŠØ© / Actes judiciaires",
    "Fonds de Commerce": "Ø§ØµÙˆÙ„ ØªØ¬Ø§Ø±ÙŠØ© / Fonds de Commerce",
    "Convocations": "Ø§Ø³ØªØ¯Ø¹Ø§Ø¡Ø§Øª / Convocations",
    "Avis aux crÃ©anciers": "Ø§Ø¹Ù„Ø§Ù† Ù„Ù„Ø¯Ø§Ø¦Ù†ÙŠÙ† / Avis aux crÃ©anciers",
    "Gestion de SociÃ©tÃ©s": "Ø§Ù„ØªØµØ±Ù ÙÙŠ Ø´Ø±ÙƒØ§Øª / Gestion de SociÃ©tÃ©s",
    "Associations, Partis, Syndicats et Syndics": "Ø¬Ù…Ø¹ÙŠØ§Øª ÙˆØ§Ø­Ø²Ø§Ø¨ ÙˆÙ†Ù‚Ø§Ø¨Ø§Øª / Associations, Partis, Syndicats et Syndics",
    "Divers": "Ù…Ø®ØªÙ„ÙØ§Øª / Divers"
}


# === PrÃ©diction des catÃ©gories
def classify_categories(json_path: Path, model_dir: Path):
    with json_path.open("r", encoding="utf-8") as f:
        articles = json.load(f)

    classifier = pipeline("text-classification", model=str(model_dir), tokenizer=str(model_dir))

    for article in tqdm(articles, desc="ðŸ“Š PrÃ©diction des catÃ©gories"):
        if not article.get("is_legal", False):
            continue

        text = preprocess_text(article["articleText"])
        if not text:
            article["categories"] = []
            continue

        try:
            result = classifier(text, truncation=True)[0]
            label = result["label"]
            label_name = category_names.get(label, "Ù…Ø®ØªÙ„ÙØ§Øª / Divers")  

            # SÃ©paration arabe / franÃ§ais
            if " / " in label_name:
                arabic, french = label_name.split(" / ", 1)
            else:
                arabic, french = label_name, label

            article["categories"] = [arabic.strip(), french.strip()]

        except Exception as e:
            print(f"âŒ Erreur pour article: {article['title']} â†’ {e}")
            article["categories"] = []

    with json_path.open("w", encoding="utf-8") as f:
        json.dump(articles, f, ensure_ascii=False, indent=4)

    print(f"\nâœ… Fichier mis Ã  jour avec catÃ©gories dans : {json_path}")
